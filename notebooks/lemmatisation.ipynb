{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Svetlana-Yatsyk/JdE_RMBLF_texto/blob/main/notebooks/lemmatisation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanza in /usr/local/lib/python3.11/site-packages (1.10.1)\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.11/site-packages (from stanza) (2.14.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from stanza) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.11/site-packages (from stanza) (4.25.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from stanza) (2.32.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from stanza) (3.4.2)\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.11/site-packages (from stanza) (2.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from stanza) (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/sy/Library/Python/3.11/lib/python/site-packages (from torch>=1.3.0->stanza) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (2025.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->stanza) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->stanza) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->stanza) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->stanza) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 434kB [00:00, 3.11MB/s]                    \n",
      "2025-10-26 23:22:35 INFO: Downloaded file to /Users/sy/stanza_resources/resources.json\n",
      "2025-10-26 23:22:35 INFO: Downloading these customized packages for language: la (Latin)...\n",
      "================================\n",
      "| Processor | Package          |\n",
      "--------------------------------\n",
      "| tokenize  | perseus          |\n",
      "| mwt       | perseus          |\n",
      "| pos       | perseus_nocharlm |\n",
      "| lemma     | perseus_nocharlm |\n",
      "| depparse  | perseus_nocharlm |\n",
      "| pretrain  | conll17          |\n",
      "================================\n",
      "\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-la/resolve/v1.10.0/models/tokenize/perseus.pt: 100%|██████████| 626k/626k [00:00<00:00, 1.25MB/s]\n",
      "2025-10-26 23:22:36 INFO: Downloaded file to /Users/sy/stanza_resources/la/tokenize/perseus.pt\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-la/resolve/v1.10.0/models/mwt/perseus.pt: 100%|██████████| 461k/461k [00:00<00:00, 525kB/s]\n",
      "2025-10-26 23:22:37 INFO: Downloaded file to /Users/sy/stanza_resources/la/mwt/perseus.pt\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-la/resolve/v1.10.0/models/pos/perseus_nocharlm.pt: 100%|██████████| 19.2M/19.2M [00:09<00:00, 2.00MB/s]\n",
      "2025-10-26 23:22:48 INFO: Downloaded file to /Users/sy/stanza_resources/la/pos/perseus_nocharlm.pt\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-la/resolve/v1.10.0/models/lemma/perseus_nocharlm.pt: 100%|██████████| 2.31M/2.31M [00:01<00:00, 1.51MB/s]\n",
      "2025-10-26 23:22:50 INFO: Downloaded file to /Users/sy/stanza_resources/la/lemma/perseus_nocharlm.pt\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-la/resolve/v1.10.0/models/depparse/perseus_nocharlm.pt: 100%|██████████| 101M/101M [00:52<00:00, 1.94MB/s] \n",
      "2025-10-26 23:23:43 INFO: Downloaded file to /Users/sy/stanza_resources/la/depparse/perseus_nocharlm.pt\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-la/resolve/v1.10.0/models/pretrain/conll17.pt: 100%|██████████| 107M/107M [00:35<00:00, 3.01MB/s] \n",
      "2025-10-26 23:24:19 INFO: Downloaded file to /Users/sy/stanza_resources/la/pretrain/conll17.pt\n",
      "2025-10-26 23:24:19 INFO: Finished downloading models and saved to /Users/sy/stanza_resources\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('la', package=\"perseus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "canticum = \"Sicut lilium inter spinas, sic amica mea inter filias. Sicut malus inter ligna silvarum, sic dilectus meus inter filios. Sub umbra illius quem desideraveram sedi, et fructus ejus dulcis gutturi meo.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 23:24:19 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 434kB [00:00, 25.0MB/s]                    \n",
      "2025-10-26 23:24:20 INFO: Downloaded file to /Users/sy/stanza_resources/resources.json\n",
      "2025-10-26 23:24:20 WARNING: Language la package perseus expects mwt, which has been added\n",
      "2025-10-26 23:24:21 INFO: Loading these models for language: la (Latin):\n",
      "================================\n",
      "| Processor | Package          |\n",
      "--------------------------------\n",
      "| tokenize  | perseus          |\n",
      "| mwt       | perseus          |\n",
      "| pos       | perseus_nocharlm |\n",
      "| lemma     | perseus_nocharlm |\n",
      "| depparse  | perseus_nocharlm |\n",
      "================================\n",
      "\n",
      "2025-10-26 23:24:21 INFO: Using device: cpu\n",
      "2025-10-26 23:24:21 INFO: Loading: tokenize\n",
      "2025-10-26 23:24:24 INFO: Loading: mwt\n",
      "2025-10-26 23:24:24 INFO: Loading: pos\n",
      "2025-10-26 23:24:28 INFO: Loading: lemma\n",
      "2025-10-26 23:24:28 INFO: Loading: depparse\n",
      "2025-10-26 23:24:29 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp_stanza = stanza.Pipeline(lang='la', package=\"perseus\", processors='tokenize,pos,lemma, depparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "canticum_lemmatised=nlp_stanza(canticum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXX Sicut lilium inter spinas, sic amica mea inter filias. XXXXX\n",
      "XXXXX Sicut malus inter ligna silvarum, sic dilectus meus inter filios. XXXXX\n",
      "XXXXX Sub umbra illius quem desideraveram sedi, et fructus ejus dulcis gutturi meo. XXXXX\n"
     ]
    }
   ],
   "source": [
    "for sent in canticum_lemmatised.sentences:\n",
    "  print(\"XXXXX \"+sent.text+\" XXXXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sicut - sicut - SCONJ\n",
      "lilium - lilius - NOUN\n",
      "inter - inter - ADP\n",
      "spinas - spina - NOUN\n",
      ", - , - PUNCT\n",
      "sic - sic - ADV\n",
      "amica - amica - NOUN\n",
      "mea - meus - DET\n",
      "inter - inter - ADP\n",
      "filias - filia - NOUN\n",
      ". - . - PUNCT\n",
      "Sicut - sicut - SCONJ\n",
      "malus - malus - ADJ\n",
      "inter - inter - ADP\n",
      "ligna - lignum - NOUN\n",
      "silvarum - silva - NOUN\n",
      ", - , - PUNCT\n",
      "sic - sic - ADV\n",
      "dilectus - diligo - VERB\n",
      "meus - meus - DET\n",
      "inter - inter - ADP\n",
      "filios - filius - NOUN\n",
      ". - . - PUNCT\n",
      "Sub - sub - ADP\n",
      "umbra - umbra - NOUN\n",
      "illius - ille - DET\n",
      "quem - qui - PRON\n",
      "desideraveram - desidero - VERB\n",
      "sedi - sedes - NOUN\n",
      ", - , - PUNCT\n",
      "et - et - CCONJ\n",
      "fructus - fructus - NOUN\n",
      "ejus - is - PRON\n",
      "dulcis - dulcis - ADJ\n",
      "gutturi - gunfero - VERB\n",
      "meo - meus - DET\n",
      ". - . - PUNCT\n"
     ]
    }
   ],
   "source": [
    "for sent in canticum_lemmatised.sentences:\n",
    "  for token in sent.words:\n",
    "    print(token.text + ' - ' + token.lemma + ' - ' + token.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-26 23:27:03--  https://raw.githubusercontent.com/OdysseusPolymetis/digital_classics_course/refs/heads/main/stopwords_lat.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 35385 (35K) [text/plain]\n",
      "stopwords_lat.txt: Read-only file system\n",
      "\n",
      "Cannot write to ‘stopwords_lat.txt’ (Read-only file system).\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/OdysseusPolymetis/digital_classics_course/refs/heads/main/stopwords_lat.txt\n",
    "stopwords = open(\"/content/stopwords_gk.txt\",'r',encoding=\"utf8\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
